{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dokyoungleee/skumldk/blob/main/convmixer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torchvision.transforms.autoaugment import RandAugment\n",
        "from timm.data.mixup import Mixup\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import time\n",
        "\n",
        "# ConvMixer 모델 정의\n",
        "def create_convmixer_cifar10(num_classes=10):\n",
        "    model = timm.models.convmixer.ConvMixer(\n",
        "        dim=128,        # Hidden Dimension\n",
        "        depth=4,        # Number of Layers\n",
        "        kernel_size=8,  # Kernel Size in Depthwise Convolution\n",
        "        patch_size=1,   # Patch Size\n",
        "        num_classes=num_classes,  # CIFAR-10 classes\n",
        "        dropout=0.1     # Dropout\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# CIFAR-10 데이터셋 준비\n",
        "def get_dataloaders(batch_size):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),  # Random crop with padding\n",
        "        transforms.RandomHorizontalFlip(),    # Horizontal Flip\n",
        "        RandAugment(num_ops=3, magnitude=9),  # RandAugment\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalization\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalization\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform_train, download=True)\n",
        "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform_test, download=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# 학습 루프 정의\n",
        "def train(model, dataloader, optimizer, criterion, device, mixup_fn):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        inputs, targets = mixup_fn(inputs, targets)  # Mixup 적용\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# 평가 루프 정의\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return total_loss / len(dataloader), correct / len(dataloader.dataset)\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "num_epochs = 150\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ConvMixer 모델 생성\n",
        "model = create_convmixer_cifar10(num_classes=10).to(device)\n",
        "\n",
        "# Mixup 설정\n",
        "mixup_fn = Mixup(\n",
        "    mixup_alpha=0.2,  # Mixup alpha 값\n",
        "    cutmix_alpha=0.3,  # CutMix alpha 값\n",
        "    prob=0.7,          # Mixup/CutMix 확률\n",
        "    label_smoothing=0.1,  # Label smoothing\n",
        "    num_classes=10     # CIFAR-10 classes\n",
        ")\n",
        "\n",
        "# 데이터 로더 준비\n",
        "train_loader, test_loader = get_dataloaders(batch_size)\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 러닝 레이트 스케줄러 정의\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "# 학습 및 평가 루프 실행\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, device, mixup_fn)\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "    scheduler.step()  # Learning rate scheduling\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_duration = end_time - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f} | Time: {epoch_duration:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls09D9S2XV1q",
        "outputId": "0a477aac-d8b1-464d-ad89-70ca49e8f916"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/150 | Train Loss: 1.8603 | Test Loss: 1.1100 | Test Accuracy: 0.6073 | Time: 70.49s\n",
            "Epoch 2/150 | Train Loss: 1.5841 | Test Loss: 0.9986 | Test Accuracy: 0.6501 | Time: 70.38s\n",
            "Epoch 3/150 | Train Loss: 1.4969 | Test Loss: 0.8076 | Test Accuracy: 0.7318 | Time: 70.90s\n",
            "Epoch 4/150 | Train Loss: 1.4492 | Test Loss: 0.7577 | Test Accuracy: 0.7502 | Time: 71.44s\n",
            "Epoch 5/150 | Train Loss: 1.4246 | Test Loss: 0.7120 | Test Accuracy: 0.7729 | Time: 71.33s\n",
            "Epoch 6/150 | Train Loss: 1.3682 | Test Loss: 0.6418 | Test Accuracy: 0.7981 | Time: 70.37s\n",
            "Epoch 7/150 | Train Loss: 1.3688 | Test Loss: 0.6581 | Test Accuracy: 0.7973 | Time: 71.88s\n",
            "Epoch 8/150 | Train Loss: 1.3354 | Test Loss: 0.5746 | Test Accuracy: 0.8123 | Time: 70.92s\n",
            "Epoch 9/150 | Train Loss: 1.3444 | Test Loss: 0.5932 | Test Accuracy: 0.8158 | Time: 70.06s\n",
            "Epoch 10/150 | Train Loss: 1.3022 | Test Loss: 0.6168 | Test Accuracy: 0.8120 | Time: 70.19s\n",
            "Epoch 11/150 | Train Loss: 1.2961 | Test Loss: 0.6138 | Test Accuracy: 0.8066 | Time: 70.55s\n",
            "Epoch 12/150 | Train Loss: 1.3282 | Test Loss: 0.5517 | Test Accuracy: 0.8281 | Time: 71.17s\n",
            "Epoch 13/150 | Train Loss: 1.2706 | Test Loss: 0.5577 | Test Accuracy: 0.8309 | Time: 70.57s\n",
            "Epoch 14/150 | Train Loss: 1.2528 | Test Loss: 0.5263 | Test Accuracy: 0.8362 | Time: 70.41s\n",
            "Epoch 15/150 | Train Loss: 1.2342 | Test Loss: 0.4976 | Test Accuracy: 0.8408 | Time: 70.18s\n",
            "Epoch 16/150 | Train Loss: 1.2842 | Test Loss: 0.5006 | Test Accuracy: 0.8475 | Time: 70.46s\n",
            "Epoch 17/150 | Train Loss: 1.2519 | Test Loss: 0.5112 | Test Accuracy: 0.8478 | Time: 70.21s\n",
            "Epoch 18/150 | Train Loss: 1.2171 | Test Loss: 0.5030 | Test Accuracy: 0.8468 | Time: 70.31s\n",
            "Epoch 19/150 | Train Loss: 1.2491 | Test Loss: 0.5238 | Test Accuracy: 0.8446 | Time: 70.58s\n",
            "Epoch 20/150 | Train Loss: 1.2629 | Test Loss: 0.5072 | Test Accuracy: 0.8520 | Time: 71.09s\n",
            "Epoch 21/150 | Train Loss: 1.2304 | Test Loss: 0.5112 | Test Accuracy: 0.8454 | Time: 71.17s\n",
            "Epoch 22/150 | Train Loss: 1.2945 | Test Loss: 0.4712 | Test Accuracy: 0.8616 | Time: 70.51s\n",
            "Epoch 23/150 | Train Loss: 1.2152 | Test Loss: 0.5315 | Test Accuracy: 0.8607 | Time: 70.34s\n",
            "Epoch 24/150 | Train Loss: 1.2310 | Test Loss: 0.5346 | Test Accuracy: 0.8396 | Time: 70.12s\n",
            "Epoch 25/150 | Train Loss: 1.1988 | Test Loss: 0.4640 | Test Accuracy: 0.8664 | Time: 70.46s\n",
            "Epoch 26/150 | Train Loss: 1.1971 | Test Loss: 0.4441 | Test Accuracy: 0.8659 | Time: 70.00s\n",
            "Epoch 27/150 | Train Loss: 1.1911 | Test Loss: 0.4805 | Test Accuracy: 0.8700 | Time: 70.33s\n",
            "Epoch 28/150 | Train Loss: 1.2069 | Test Loss: 0.4450 | Test Accuracy: 0.8708 | Time: 71.21s\n",
            "Epoch 29/150 | Train Loss: 1.1944 | Test Loss: 0.4677 | Test Accuracy: 0.8678 | Time: 70.91s\n",
            "Epoch 30/150 | Train Loss: 1.1907 | Test Loss: 0.4820 | Test Accuracy: 0.8615 | Time: 70.20s\n",
            "Epoch 31/150 | Train Loss: 1.1831 | Test Loss: 0.4685 | Test Accuracy: 0.8539 | Time: 70.36s\n",
            "Epoch 32/150 | Train Loss: 1.1760 | Test Loss: 0.4373 | Test Accuracy: 0.8712 | Time: 70.41s\n",
            "Epoch 33/150 | Train Loss: 1.2091 | Test Loss: 0.4497 | Test Accuracy: 0.8735 | Time: 70.95s\n",
            "Epoch 34/150 | Train Loss: 1.1951 | Test Loss: 0.4684 | Test Accuracy: 0.8727 | Time: 71.53s\n",
            "Epoch 35/150 | Train Loss: 1.1820 | Test Loss: 0.4518 | Test Accuracy: 0.8662 | Time: 70.15s\n",
            "Epoch 36/150 | Train Loss: 1.1834 | Test Loss: 0.4161 | Test Accuracy: 0.8852 | Time: 70.48s\n",
            "Epoch 37/150 | Train Loss: 1.1402 | Test Loss: 0.4540 | Test Accuracy: 0.8764 | Time: 71.13s\n",
            "Epoch 38/150 | Train Loss: 1.1737 | Test Loss: 0.4454 | Test Accuracy: 0.8766 | Time: 71.55s\n",
            "Epoch 39/150 | Train Loss: 1.1535 | Test Loss: 0.4247 | Test Accuracy: 0.8827 | Time: 70.69s\n",
            "Epoch 40/150 | Train Loss: 1.2268 | Test Loss: 0.4346 | Test Accuracy: 0.8783 | Time: 70.62s\n",
            "Epoch 41/150 | Train Loss: 1.1773 | Test Loss: 0.4165 | Test Accuracy: 0.8871 | Time: 71.04s\n",
            "Epoch 42/150 | Train Loss: 1.1692 | Test Loss: 0.4389 | Test Accuracy: 0.8713 | Time: 71.04s\n",
            "Epoch 43/150 | Train Loss: 1.1857 | Test Loss: 0.4590 | Test Accuracy: 0.8737 | Time: 71.10s\n",
            "Epoch 44/150 | Train Loss: 1.1623 | Test Loss: 0.3970 | Test Accuracy: 0.8903 | Time: 71.34s\n",
            "Epoch 45/150 | Train Loss: 1.1600 | Test Loss: 0.4221 | Test Accuracy: 0.8845 | Time: 72.06s\n",
            "Epoch 46/150 | Train Loss: 1.1773 | Test Loss: 0.4241 | Test Accuracy: 0.8828 | Time: 71.17s\n",
            "Epoch 47/150 | Train Loss: 1.1757 | Test Loss: 0.4000 | Test Accuracy: 0.8881 | Time: 70.92s\n",
            "Epoch 48/150 | Train Loss: 1.1530 | Test Loss: 0.4218 | Test Accuracy: 0.8857 | Time: 70.83s\n",
            "Epoch 49/150 | Train Loss: 1.1576 | Test Loss: 0.4258 | Test Accuracy: 0.8931 | Time: 71.40s\n",
            "Epoch 50/150 | Train Loss: 1.1554 | Test Loss: 0.4270 | Test Accuracy: 0.8868 | Time: 71.65s\n",
            "Epoch 51/150 | Train Loss: 1.1915 | Test Loss: 0.4128 | Test Accuracy: 0.8885 | Time: 71.88s\n",
            "Epoch 52/150 | Train Loss: 1.1593 | Test Loss: 0.3925 | Test Accuracy: 0.8951 | Time: 71.54s\n",
            "Epoch 53/150 | Train Loss: 1.1528 | Test Loss: 0.4187 | Test Accuracy: 0.8870 | Time: 72.14s\n",
            "Epoch 54/150 | Train Loss: 1.1777 | Test Loss: 0.4107 | Test Accuracy: 0.8895 | Time: 71.12s\n",
            "Epoch 55/150 | Train Loss: 1.1833 | Test Loss: 0.3884 | Test Accuracy: 0.8929 | Time: 71.77s\n",
            "Epoch 56/150 | Train Loss: 1.1451 | Test Loss: 0.3856 | Test Accuracy: 0.8939 | Time: 71.01s\n",
            "Epoch 57/150 | Train Loss: 1.1905 | Test Loss: 0.4073 | Test Accuracy: 0.8899 | Time: 71.51s\n",
            "Epoch 58/150 | Train Loss: 1.1679 | Test Loss: 0.4005 | Test Accuracy: 0.8923 | Time: 71.36s\n",
            "Epoch 59/150 | Train Loss: 1.1642 | Test Loss: 0.3951 | Test Accuracy: 0.8938 | Time: 72.05s\n",
            "Epoch 60/150 | Train Loss: 1.1646 | Test Loss: 0.3973 | Test Accuracy: 0.8905 | Time: 71.94s\n",
            "Epoch 61/150 | Train Loss: 1.1132 | Test Loss: 0.3956 | Test Accuracy: 0.8930 | Time: 71.08s\n",
            "Epoch 62/150 | Train Loss: 1.1591 | Test Loss: 0.4148 | Test Accuracy: 0.8885 | Time: 70.92s\n",
            "Epoch 63/150 | Train Loss: 1.1163 | Test Loss: 0.4010 | Test Accuracy: 0.8926 | Time: 71.15s\n",
            "Epoch 64/150 | Train Loss: 1.1236 | Test Loss: 0.3654 | Test Accuracy: 0.8997 | Time: 70.82s\n",
            "Epoch 65/150 | Train Loss: 1.1541 | Test Loss: 0.3930 | Test Accuracy: 0.8930 | Time: 71.30s\n",
            "Epoch 66/150 | Train Loss: 1.1221 | Test Loss: 0.3874 | Test Accuracy: 0.8959 | Time: 71.45s\n",
            "Epoch 67/150 | Train Loss: 1.1397 | Test Loss: 0.3956 | Test Accuracy: 0.8947 | Time: 71.94s\n",
            "Epoch 68/150 | Train Loss: 1.1374 | Test Loss: 0.4081 | Test Accuracy: 0.8950 | Time: 71.07s\n",
            "Epoch 69/150 | Train Loss: 1.1475 | Test Loss: 0.3945 | Test Accuracy: 0.8974 | Time: 71.03s\n",
            "Epoch 70/150 | Train Loss: 1.1468 | Test Loss: 0.3875 | Test Accuracy: 0.8980 | Time: 70.64s\n",
            "Epoch 71/150 | Train Loss: 1.1223 | Test Loss: 0.3988 | Test Accuracy: 0.8954 | Time: 71.45s\n",
            "Epoch 72/150 | Train Loss: 1.1723 | Test Loss: 0.3998 | Test Accuracy: 0.8950 | Time: 70.78s\n",
            "Epoch 73/150 | Train Loss: 1.1145 | Test Loss: 0.3820 | Test Accuracy: 0.8979 | Time: 71.12s\n",
            "Epoch 74/150 | Train Loss: 1.1240 | Test Loss: 0.3739 | Test Accuracy: 0.8980 | Time: 71.74s\n",
            "Epoch 75/150 | Train Loss: 1.1105 | Test Loss: 0.3798 | Test Accuracy: 0.8988 | Time: 71.60s\n",
            "Epoch 76/150 | Train Loss: 1.1064 | Test Loss: 0.3699 | Test Accuracy: 0.8999 | Time: 71.00s\n",
            "Epoch 77/150 | Train Loss: 1.1129 | Test Loss: 0.3634 | Test Accuracy: 0.8992 | Time: 71.87s\n",
            "Epoch 78/150 | Train Loss: 1.1049 | Test Loss: 0.3867 | Test Accuracy: 0.8973 | Time: 70.95s\n",
            "Epoch 79/150 | Train Loss: 1.1147 | Test Loss: 0.3935 | Test Accuracy: 0.8954 | Time: 71.01s\n",
            "Epoch 80/150 | Train Loss: 1.0865 | Test Loss: 0.3897 | Test Accuracy: 0.9011 | Time: 70.93s\n",
            "Epoch 81/150 | Train Loss: 1.1101 | Test Loss: 0.4044 | Test Accuracy: 0.8954 | Time: 71.76s\n",
            "Epoch 82/150 | Train Loss: 1.1205 | Test Loss: 0.3715 | Test Accuracy: 0.9023 | Time: 73.07s\n",
            "Epoch 83/150 | Train Loss: 1.1217 | Test Loss: 0.3634 | Test Accuracy: 0.8994 | Time: 71.97s\n",
            "Epoch 84/150 | Train Loss: 1.1012 | Test Loss: 0.3752 | Test Accuracy: 0.9030 | Time: 71.12s\n",
            "Epoch 85/150 | Train Loss: 1.1182 | Test Loss: 0.3721 | Test Accuracy: 0.9033 | Time: 71.14s\n",
            "Epoch 86/150 | Train Loss: 1.0947 | Test Loss: 0.3557 | Test Accuracy: 0.9042 | Time: 70.67s\n",
            "Epoch 87/150 | Train Loss: 1.0877 | Test Loss: 0.3645 | Test Accuracy: 0.9018 | Time: 70.82s\n",
            "Epoch 88/150 | Train Loss: 1.0949 | Test Loss: 0.3646 | Test Accuracy: 0.9034 | Time: 71.00s\n",
            "Epoch 89/150 | Train Loss: 1.1073 | Test Loss: 0.3741 | Test Accuracy: 0.8999 | Time: 71.07s\n",
            "Epoch 90/150 | Train Loss: 1.1145 | Test Loss: 0.3674 | Test Accuracy: 0.9051 | Time: 71.57s\n",
            "Epoch 91/150 | Train Loss: 1.1257 | Test Loss: 0.3760 | Test Accuracy: 0.9017 | Time: 71.78s\n",
            "Epoch 92/150 | Train Loss: 1.0927 | Test Loss: 0.3656 | Test Accuracy: 0.9038 | Time: 71.61s\n",
            "Epoch 93/150 | Train Loss: 1.1163 | Test Loss: 0.3784 | Test Accuracy: 0.9039 | Time: 71.16s\n",
            "Epoch 94/150 | Train Loss: 1.0475 | Test Loss: 0.3599 | Test Accuracy: 0.9048 | Time: 71.07s\n",
            "Epoch 95/150 | Train Loss: 1.1144 | Test Loss: 0.3763 | Test Accuracy: 0.9050 | Time: 71.02s\n",
            "Epoch 96/150 | Train Loss: 1.0691 | Test Loss: 0.3715 | Test Accuracy: 0.9043 | Time: 71.05s\n",
            "Epoch 97/150 | Train Loss: 1.0979 | Test Loss: 0.3700 | Test Accuracy: 0.9049 | Time: 71.11s\n",
            "Epoch 98/150 | Train Loss: 1.0810 | Test Loss: 0.3707 | Test Accuracy: 0.9042 | Time: 72.25s\n",
            "Epoch 99/150 | Train Loss: 1.0760 | Test Loss: 0.3660 | Test Accuracy: 0.9065 | Time: 71.62s\n",
            "Epoch 100/150 | Train Loss: 1.0682 | Test Loss: 0.3643 | Test Accuracy: 0.9055 | Time: 71.02s\n",
            "Epoch 101/150 | Train Loss: 1.0568 | Test Loss: 0.3566 | Test Accuracy: 0.9048 | Time: 71.69s\n",
            "Epoch 102/150 | Train Loss: 1.1177 | Test Loss: 0.3520 | Test Accuracy: 0.9055 | Time: 71.32s\n",
            "Epoch 103/150 | Train Loss: 1.0866 | Test Loss: 0.3658 | Test Accuracy: 0.9036 | Time: 70.89s\n",
            "Epoch 104/150 | Train Loss: 1.0841 | Test Loss: 0.3628 | Test Accuracy: 0.9087 | Time: 71.00s\n",
            "Epoch 105/150 | Train Loss: 1.0920 | Test Loss: 0.3554 | Test Accuracy: 0.9073 | Time: 71.71s\n",
            "Epoch 106/150 | Train Loss: 1.0490 | Test Loss: 0.3638 | Test Accuracy: 0.9051 | Time: 71.79s\n",
            "Epoch 107/150 | Train Loss: 1.0923 | Test Loss: 0.3523 | Test Accuracy: 0.9080 | Time: 71.28s\n",
            "Epoch 108/150 | Train Loss: 1.0839 | Test Loss: 0.3491 | Test Accuracy: 0.9078 | Time: 71.20s\n",
            "Epoch 109/150 | Train Loss: 1.0371 | Test Loss: 0.3580 | Test Accuracy: 0.9063 | Time: 70.86s\n",
            "Epoch 110/150 | Train Loss: 1.0695 | Test Loss: 0.3700 | Test Accuracy: 0.9077 | Time: 71.25s\n",
            "Epoch 111/150 | Train Loss: 1.1073 | Test Loss: 0.3654 | Test Accuracy: 0.9072 | Time: 71.54s\n",
            "Epoch 112/150 | Train Loss: 1.0740 | Test Loss: 0.3535 | Test Accuracy: 0.9057 | Time: 71.59s\n",
            "Epoch 113/150 | Train Loss: 1.0913 | Test Loss: 0.3568 | Test Accuracy: 0.9066 | Time: 71.79s\n",
            "Epoch 114/150 | Train Loss: 1.0993 | Test Loss: 0.3567 | Test Accuracy: 0.9089 | Time: 71.65s\n",
            "Epoch 115/150 | Train Loss: 1.0795 | Test Loss: 0.3662 | Test Accuracy: 0.9035 | Time: 71.32s\n",
            "Epoch 116/150 | Train Loss: 1.0823 | Test Loss: 0.3600 | Test Accuracy: 0.9069 | Time: 70.75s\n",
            "Epoch 117/150 | Train Loss: 1.0699 | Test Loss: 0.3656 | Test Accuracy: 0.9075 | Time: 71.21s\n",
            "Epoch 118/150 | Train Loss: 1.1180 | Test Loss: 0.3582 | Test Accuracy: 0.9061 | Time: 70.62s\n",
            "Epoch 119/150 | Train Loss: 1.0331 | Test Loss: 0.3493 | Test Accuracy: 0.9089 | Time: 71.96s\n",
            "Epoch 120/150 | Train Loss: 1.0976 | Test Loss: 0.3704 | Test Accuracy: 0.9063 | Time: 72.27s\n",
            "Epoch 121/150 | Train Loss: 1.0899 | Test Loss: 0.3694 | Test Accuracy: 0.9062 | Time: 71.86s\n",
            "Epoch 122/150 | Train Loss: 1.0483 | Test Loss: 0.3664 | Test Accuracy: 0.9057 | Time: 71.06s\n",
            "Epoch 123/150 | Train Loss: 1.0820 | Test Loss: 0.3620 | Test Accuracy: 0.9070 | Time: 70.66s\n",
            "Epoch 124/150 | Train Loss: 1.0744 | Test Loss: 0.3756 | Test Accuracy: 0.9079 | Time: 70.79s\n",
            "Epoch 125/150 | Train Loss: 1.1015 | Test Loss: 0.3698 | Test Accuracy: 0.9074 | Time: 70.86s\n",
            "Epoch 126/150 | Train Loss: 1.0777 | Test Loss: 0.3590 | Test Accuracy: 0.9087 | Time: 71.34s\n",
            "Epoch 127/150 | Train Loss: 1.0402 | Test Loss: 0.3593 | Test Accuracy: 0.9094 | Time: 72.05s\n",
            "Epoch 128/150 | Train Loss: 1.0898 | Test Loss: 0.3608 | Test Accuracy: 0.9091 | Time: 71.90s\n",
            "Epoch 129/150 | Train Loss: 1.0831 | Test Loss: 0.3572 | Test Accuracy: 0.9089 | Time: 71.03s\n",
            "Epoch 130/150 | Train Loss: 1.0659 | Test Loss: 0.3605 | Test Accuracy: 0.9083 | Time: 70.93s\n",
            "Epoch 131/150 | Train Loss: 1.0886 | Test Loss: 0.3665 | Test Accuracy: 0.9103 | Time: 71.03s\n",
            "Epoch 132/150 | Train Loss: 1.0638 | Test Loss: 0.3520 | Test Accuracy: 0.9103 | Time: 70.83s\n",
            "Epoch 133/150 | Train Loss: 1.0741 | Test Loss: 0.3549 | Test Accuracy: 0.9108 | Time: 71.50s\n",
            "Epoch 134/150 | Train Loss: 1.0721 | Test Loss: 0.3619 | Test Accuracy: 0.9097 | Time: 71.97s\n",
            "Epoch 135/150 | Train Loss: 1.0320 | Test Loss: 0.3471 | Test Accuracy: 0.9089 | Time: 71.29s\n",
            "Epoch 136/150 | Train Loss: 1.0926 | Test Loss: 0.3549 | Test Accuracy: 0.9096 | Time: 70.70s\n",
            "Epoch 137/150 | Train Loss: 1.0798 | Test Loss: 0.3538 | Test Accuracy: 0.9097 | Time: 71.02s\n",
            "Epoch 138/150 | Train Loss: 1.0597 | Test Loss: 0.3542 | Test Accuracy: 0.9086 | Time: 70.95s\n",
            "Epoch 139/150 | Train Loss: 1.0928 | Test Loss: 0.3512 | Test Accuracy: 0.9087 | Time: 71.14s\n",
            "Epoch 140/150 | Train Loss: 1.0697 | Test Loss: 0.3532 | Test Accuracy: 0.9086 | Time: 71.30s\n",
            "Epoch 141/150 | Train Loss: 1.0815 | Test Loss: 0.3448 | Test Accuracy: 0.9096 | Time: 71.58s\n",
            "Epoch 142/150 | Train Loss: 1.0626 | Test Loss: 0.3590 | Test Accuracy: 0.9096 | Time: 71.20s\n",
            "Epoch 143/150 | Train Loss: 1.0713 | Test Loss: 0.3491 | Test Accuracy: 0.9099 | Time: 71.29s\n",
            "Epoch 144/150 | Train Loss: 1.0797 | Test Loss: 0.3581 | Test Accuracy: 0.9090 | Time: 71.22s\n",
            "Epoch 145/150 | Train Loss: 1.1153 | Test Loss: 0.3614 | Test Accuracy: 0.9089 | Time: 72.53s\n",
            "Epoch 146/150 | Train Loss: 1.0755 | Test Loss: 0.3694 | Test Accuracy: 0.9085 | Time: 71.17s\n",
            "Epoch 147/150 | Train Loss: 1.0746 | Test Loss: 0.3639 | Test Accuracy: 0.9096 | Time: 71.60s\n",
            "Epoch 148/150 | Train Loss: 1.0963 | Test Loss: 0.3553 | Test Accuracy: 0.9090 | Time: 71.87s\n",
            "Epoch 149/150 | Train Loss: 1.0664 | Test Loss: 0.3513 | Test Accuracy: 0.9087 | Time: 71.19s\n",
            "Epoch 150/150 | Train Loss: 1.0749 | Test Loss: 0.3567 | Test Accuracy: 0.9078 | Time: 71.07s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colaboratory에 오신 것을 환영합니다",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}